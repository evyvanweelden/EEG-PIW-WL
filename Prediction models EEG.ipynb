{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c846cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code created by Carl van Beek\n",
    "#last updated on 16-10-2023\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4311d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#Data is in long format with columns for EEG spectral power values (baseline-corrected or absolute), Order, Subject, Trial number, and Condition.\n",
    "\n",
    "Alpha_norm_table = pd.read_csv(\"C:/Users/.../Table_alpha_baselinecorrectedvalues.csv\")\n",
    "Beta_norm_table = pd.read_csv(\"C:/Users/.../Table_beta_baselinecorrectedvalues.csv\")\n",
    "Theta_norm_table = pd.read_csv(\"C:/Users/.../Table_theta_baselinecorrectedvalues.csv\")\n",
    "Engagement_norm_table = pd.read_csv(\"C:/Users/.../Table_engagement_baselinecorrectedvalues.csv\")\n",
    "\n",
    "Alpha_absolute_table = pd.read_csv(\"C:/Users/.../Table_alpha_absolutevalues.csv\")\n",
    "Beta_absolute_table = pd.read_csv(\"C:/Users/.../Table_beta_absolutevalues.csv\")\n",
    "Theta_absolute_table = pd.read_csv(\"C:/Users/.../Table_theta_absolutevalues.csv\")\n",
    "Engagement_absolute_table = pd.read_csv(\"C:/Users/.../Table_engagement_absolutevalues.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7ec587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Alpha_FP1  Alpha_FP2  Alpha_AF3  Alpha_AF4  Alpha_F7  Alpha_F3  Alpha_Fz  \\\n",
      "0    1.013721   1.327482   0.450079   0.544898  0.374854  0.556412  0.553690   \n",
      "1    0.977242   1.256911   0.405964   0.468593  0.357436  0.487161  0.485874   \n",
      "2    0.956857   1.230577   0.440352   0.491417  0.377880  0.543356  0.538828   \n",
      "3    1.044784   1.321664   0.536318   0.602484  0.411094  0.592916  0.639552   \n",
      "4    0.985492   1.257248   0.533000   0.574808  0.401093  0.656708  0.668012   \n",
      "..        ...        ...        ...        ...       ...       ...       ...   \n",
      "67   1.747234   4.015614   0.356219   0.854112  0.442396  0.100220  0.122624   \n",
      "68   2.072914   4.693699   0.315417   0.930107  0.448993  0.083244  0.102538   \n",
      "69   1.394316   2.727770   0.328664   0.808801  0.394015  0.089394  0.107687   \n",
      "70   1.375063   2.713285   0.357637   1.424793  0.439692  0.089038  0.106762   \n",
      "71   1.409065   2.782531   0.377305   1.343245  0.508259  0.096477  0.111789   \n",
      "\n",
      "    Alpha_F4  Alpha_F8  Alpha_FC5  ...  Engagement_P3  Engagement_Pz  \\\n",
      "0   0.348264  0.753031   0.237842  ...       0.128258       0.082802   \n",
      "1   0.296442  0.695761   0.200388  ...       0.127524       0.087127   \n",
      "2   0.299578  0.766654   0.222048  ...       0.144870       0.087573   \n",
      "3   0.398113  1.194073   0.275543  ...       0.122251       0.078260   \n",
      "4   0.378865  0.761262   0.281592  ...       0.116440       0.079660   \n",
      "..       ...       ...        ...  ...            ...            ...   \n",
      "67  0.162900  0.382922   0.444934  ...       0.215918       0.152789   \n",
      "68  0.192307  0.385758   0.481270  ...       0.228131       0.150850   \n",
      "69  0.212286  0.313645   0.472843  ...       0.236327       0.149657   \n",
      "70  0.221741  0.363425   0.455894  ...       0.223265       0.175279   \n",
      "71  0.229255  0.404401   0.491570  ...       0.215318       0.149299   \n",
      "\n",
      "    Engagement_P4  Engagement_P8  Engagement_PO7  Engagement_PO3  \\\n",
      "0        0.151091       0.158588        0.143698        0.097191   \n",
      "1        0.141002       0.154538        0.146913        0.099001   \n",
      "2        0.122761       0.129215        0.146026        0.116423   \n",
      "3        0.119634       0.108339        0.119646        0.096719   \n",
      "4        0.112434       0.100532        0.131312        0.096096   \n",
      "..            ...            ...             ...             ...   \n",
      "67       0.148032       0.226541        0.180147        0.177460   \n",
      "68       0.225359       0.244507        0.371310        0.158830   \n",
      "69       0.268894       0.252154        0.316127        0.158966   \n",
      "70       0.248842       0.274647        0.319594        0.175809   \n",
      "71       0.206518       0.274221        0.318235        0.177107   \n",
      "\n",
      "    Engagement_PO4  Engagement_PO8  Engagement_Oz  Condition  \n",
      "0         0.097887        0.121562       0.099573          2  \n",
      "1         0.095176        0.119996       0.101377          1  \n",
      "2         0.091358        0.106137       0.095420          1  \n",
      "3         0.090207        0.102363       0.086569          2  \n",
      "4         0.092079        0.092947       0.084560          2  \n",
      "..             ...             ...            ...        ...  \n",
      "67        0.163181        0.200640       0.240424          1  \n",
      "68        0.261565        0.331322       0.297219          1  \n",
      "69        0.307487        0.415598       0.400234          2  \n",
      "70        0.300056        0.424898       0.412937          2  \n",
      "71        0.230508        0.366256       0.348007          1  \n",
      "\n",
      "[72 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "#create tables containing only features\n",
    "#new_duty_aggr_table = duty_aggr_table.drop(columns = ['Subject','Trial', 'Condition'])\n",
    "\n",
    "new_Alpha_norm_table = Alpha_norm_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "new_Beta_norm_table = Beta_norm_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "new_Theta_norm_table = Theta_norm_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "new_Engagement_norm_table = Engagement_norm_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "\n",
    "new_Alpha_absolute_table = Alpha_absolute_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "new_Beta_absolute_table = Beta_absolute_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "new_Theta_absolute_table = Theta_absolute_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "new_Engagement_absolute_table = Engagement_absolute_table.drop(columns = ['Order','Subject','Trial', 'Condition'])\n",
    "\n",
    "#concatenate all features into a single feature table, making a distinction between a table with and without stick data\n",
    "full_EEG_norm_table = pd.concat([new_Alpha_norm_table,new_Beta_norm_table,new_Theta_norm_table,new_Engagement_norm_table], axis=1)\n",
    "#full_norm_table = pd.concat([full_EEG_norm_table,new_duty_aggr_table], axis = 1 )\n",
    "\n",
    "full_EEG_absolute_table = pd.concat([new_Alpha_absolute_table,new_Beta_absolute_table,new_Theta_absolute_table,new_Engagement_absolute_table], axis=1)\n",
    "#full_absolute_table = pd.concat([full_EEG_absolute_table,new_duty_aggr_table], axis = 1 )\n",
    "\n",
    "#get features\n",
    "y = Alpha_norm_table['Condition'] # prediction labels, they are the same in all tables, alpha_norm is just randomly used\n",
    "\n",
    "function_test_table = pd.concat([full_EEG_absolute_table,y], axis = 1)\n",
    "print(function_test_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb4fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe should have columns: 'Condition' and Alpha, Beta, Theta and Engagement values\n",
    "#for all channels. In the case of 12 x 6 trials and 32 channels, this would be a 72 rows x 129 columns dataframe\n",
    "#Order, Subject and Trial are not used in this function, but could be used in other applications\n",
    "def workload_predictor(df):\n",
    "    X_EEG = df.drop(columns = ['Condition'])\n",
    "    #Make sure there is a column called 'Condition'. Could be replaced by an integer if there is a standard for that.\n",
    "    y = df['Condition']\n",
    "    #first create the RFE algorithm\n",
    "    SVM = SVC(kernel = 'linear',C = 1,gamma = 0.1) #Choose a classifier to perform RFE\n",
    "    SVM_RFE = RFE(SVM,n_features_to_select = 10) #Perform RFE\n",
    "    SVM_RFE.fit(X_EEG,y) \n",
    "\n",
    "    #View which features got selected\n",
    "    selected_EEG = X_EEG.columns[SVM_RFE.support_]\n",
    "    print(\"Selected features: \", selected_EEG)\n",
    "\n",
    "\n",
    "    #Transform the original X-data to only retain the selected features\n",
    "    X_RFE_EEG = SVM_RFE.transform(X_EEG)\n",
    "\n",
    "    #global value to keep track of the accuracy of each iteration\n",
    "    all_accuracies_EEG = []\n",
    "    all_f1_EEG = []\n",
    "    all_precision_EEG = []\n",
    "    all_recall_EEG = []\n",
    "\n",
    "    #perform the training and testing 10 times, to rule out chance due to the small dataset\n",
    "    for i in range(1,11):\n",
    "        #split into 70-30 training and testing for RFE\n",
    "        X_RFE_train_EEG, X_RFE_test_EEG, y_train, y_test = train_test_split(X_RFE_EEG, y, test_size = 0.3)\n",
    "\n",
    "        #gridsearch for all models of the first level in the stacking classifier\n",
    "        rf_params = {'n_estimators': [10, 25, 50, 100,200], 'max_depth': [None, 5, 10, 15]}\n",
    "        RF_EEG = RandomForestClassifier() #Check literature\n",
    "        rf_grid_EEG = GridSearchCV(RF_EEG, rf_params, cv=5, n_jobs=-1)\n",
    "        rf_grid_EEG.fit(X_RFE_train_EEG,y_train)\n",
    "\n",
    "        svm_params = {'C': [0.01, 0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10, 100]}\n",
    "        svm_EEG = SVC()\n",
    "        svm_grid_EEG = GridSearchCV(svm_EEG, svm_params, cv=5, n_jobs=-1)\n",
    "        svm_grid_EEG.fit(X_RFE_train_EEG,y_train)\n",
    "\n",
    "        lr_params = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['none','l2']}\n",
    "        lr_EEG = LogisticRegression()\n",
    "        lr_grid_EEG = GridSearchCV(lr_EEG, lr_params, cv=5, n_jobs=-1)\n",
    "        lr_grid_EEG.fit(X_RFE_train_EEG,y_train)\n",
    "\n",
    "        #variable to input as the first level in the stacking classifier\n",
    "        estimators_EEG = [('rf', rf_grid_EEG),('svc', svm_grid_EEG),('lr', lr_grid_EEG)]\n",
    "\n",
    "        #gridsearch for the second level of the stacking model\n",
    "        second_level_params_EEG = {'C': [0.01, 0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 10, 100]}\n",
    "        second_level_model_EEG = SVC()\n",
    "        second_level_grid_EEG = GridSearchCV(second_level_model_EEG, second_level_params_EEG, cv=5, n_jobs=-1)\n",
    "        second_level_grid_EEG.fit(X_RFE_train_EEG,y_train)\n",
    "\n",
    "        #Create the stacking classifier\n",
    "        sclf_EEG = StackingClassifier(estimators=estimators_EEG, final_estimator=second_level_grid_EEG)\n",
    "        sclf_EEG.fit(X_RFE_train_EEG, y_train)\n",
    "\n",
    "        prediction = sclf_EEG.predict(X_RFE_test_EEG)\n",
    "        #get model perfromance\n",
    "        accuracy_EEG = accuracy_score(y_test, prediction)\n",
    "        f1_EEG = f1_score(y_test, prediction)\n",
    "        precision_EEG = precision_score(y_test, prediction)\n",
    "        recall_EEG = recall_score(y_test, prediction)\n",
    "        #add the performance metrics to their global list to obtain averages later\n",
    "        all_accuracies_EEG.append(accuracy_EEG)\n",
    "        all_f1_EEG.append(f1_EEG)\n",
    "        all_precision_EEG.append(precision_EEG)\n",
    "        all_recall_EEG.append(recall_EEG)\n",
    "        #print out the metrics for the current iteration\n",
    "        print(\"Accuracy test number \", i, \": \", accuracy_EEG)\n",
    "        print(\"F1 score test number \", i, \": \", f1_EEG)\n",
    "        print(\"Precision test number \", i, \": \", precision_EEG)\n",
    "        print(\"Recall test number \", i, \": \", recall_EEG)\n",
    "        #obtain the chosen hyperparameters\n",
    "        print(\"Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number \",i,\": \",rf_grid_EEG.best_params_)\n",
    "        print(\"Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number \",i,\": \",svm_grid_EEG.best_params_)\n",
    "        print(\"Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number \",i,\": \",lr_grid_EEG.best_params_)\n",
    "        print(\"Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number \",i,\": \",second_level_grid_EEG.best_params_)\n",
    "\n",
    "    #print out the average model evaluation scores of all iterations\n",
    "    print(\"Average accuracy score\", np.mean(all_accuracies_EEG))\n",
    "    print(\"Average f1 score\", np.mean(all_f1_EEG))\n",
    "    print(\"Average precision\", np.mean(all_precision_EEG))\n",
    "    print(\"Average recall\", np.mean(all_recall_EEG))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e71be8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:  Index(['Alpha_P8', 'Beta_FP2', 'Beta_F8', 'Beta_P8', 'Theta_FP1', 'Theta_T7',\n",
      "       'Theta_CP6', 'Theta_Oz', 'Engagement_T8', 'Engagement_P8'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  1 :  0.6363636363636364\n",
      "F1 score test number  1 :  0.6363636363636364\n",
      "Precision test number  1 :  0.6363636363636364\n",
      "Recall test number  1 :  0.6363636363636364\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  1 :  {'max_depth': 10, 'n_estimators': 25}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  1 :  {'C': 10, 'gamma': 1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  1 :  {'C': 0.01, 'penalty': 'none'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  1 :  {'C': 10, 'gamma': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  2 :  0.8636363636363636\n",
      "F1 score test number  2 :  0.8695652173913043\n",
      "Precision test number  2 :  0.8333333333333334\n",
      "Recall test number  2 :  0.9090909090909091\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  2 :  {'max_depth': None, 'n_estimators': 25}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  2 :  {'C': 10, 'gamma': 1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  2 :  {'C': 10, 'penalty': 'l2'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  2 :  {'C': 10, 'gamma': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  3 :  0.7272727272727273\n",
      "F1 score test number  3 :  0.7272727272727273\n",
      "Precision test number  3 :  0.7272727272727273\n",
      "Recall test number  3 :  0.7272727272727273\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  3 :  {'max_depth': None, 'n_estimators': 100}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  3 :  {'C': 100, 'gamma': 0.1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  3 :  {'C': 100, 'penalty': 'l2'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  3 :  {'C': 100, 'gamma': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  4 :  0.9545454545454546\n",
      "F1 score test number  4 :  0.9565217391304348\n",
      "Precision test number  4 :  0.9166666666666666\n",
      "Recall test number  4 :  1.0\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  4 :  {'max_depth': None, 'n_estimators': 10}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  4 :  {'C': 100, 'gamma': 0.1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  4 :  {'C': 100, 'penalty': 'l2'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  4 :  {'C': 100, 'gamma': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  5 :  0.7272727272727273\n",
      "F1 score test number  5 :  0.8000000000000002\n",
      "Precision test number  5 :  0.9230769230769231\n",
      "Recall test number  5 :  0.7058823529411765\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  5 :  {'max_depth': 10, 'n_estimators': 50}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  5 :  {'C': 100, 'gamma': 0.1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  5 :  {'C': 100, 'penalty': 'l2'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  5 :  {'C': 100, 'gamma': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  6 :  0.8636363636363636\n",
      "F1 score test number  6 :  0.888888888888889\n",
      "Precision test number  6 :  1.0\n",
      "Recall test number  6 :  0.8\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  6 :  {'max_depth': None, 'n_estimators': 50}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  6 :  {'C': 100, 'gamma': 1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  6 :  {'C': 100, 'penalty': 'l2'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  6 :  {'C': 100, 'gamma': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  7 :  0.7727272727272727\n",
      "F1 score test number  7 :  0.761904761904762\n",
      "Precision test number  7 :  0.8\n",
      "Recall test number  7 :  0.7272727272727273\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  7 :  {'max_depth': 5, 'n_estimators': 10}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  7 :  {'C': 100, 'gamma': 0.1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  7 :  {'C': 100, 'penalty': 'l2'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  7 :  {'C': 100, 'gamma': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  8 :  0.7272727272727273\n",
      "F1 score test number  8 :  0.7\n",
      "Precision test number  8 :  0.7\n",
      "Recall test number  8 :  0.7\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  8 :  {'max_depth': None, 'n_estimators': 25}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  8 :  {'C': 100, 'gamma': 0.1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  8 :  {'C': 100, 'penalty': 'l2'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  8 :  {'C': 100, 'gamma': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  9 :  0.5909090909090909\n",
      "F1 score test number  9 :  0.6086956521739131\n",
      "Precision test number  9 :  0.5\n",
      "Recall test number  9 :  0.7777777777777778\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  9 :  {'max_depth': 15, 'n_estimators': 10}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  9 :  {'C': 100, 'gamma': 1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  9 :  {'C': 0.01, 'penalty': 'none'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  9 :  {'C': 100, 'gamma': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test number  10 :  0.9090909090909091\n",
      "F1 score test number  10 :  0.9230769230769231\n",
      "Precision test number  10 :  0.9230769230769231\n",
      "Recall test number  10 :  0.9230769230769231\n",
      "Chosen parameters for the random forest model in the first level of the stacking classifier for iteration number  10 :  {'max_depth': 10, 'n_estimators': 25}\n",
      "Chosen parameters for the SVM model in the first level of the stacking classifier for iteration number  10 :  {'C': 100, 'gamma': 0.1}\n",
      "Chosen parameters for the Logistic regression model in the first level of the stacking classifier for iteration number  10 :  {'C': 0.01, 'penalty': 'none'}\n",
      "Chosen parameters for the SVM model in the second level of the stacking classifier for iteration number  10 :  {'C': 100, 'gamma': 0.1}\n",
      "Average accuracy score 0.7772727272727272\n",
      "Average f1 score 0.787228954620259\n",
      "Average precision 0.795979020979021\n",
      "Average recall 0.7906737053795877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\evyva\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "workload_predictor(function_test_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc690055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
